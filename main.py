import os
import logging
import requests
from dotenv import load_dotenv
from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters

# --- 1. CONFIGURACIÃ“N DE LOGS ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- 2. CARGA DE VARIABLES ---
load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
MODEL_NAME = os.getenv("MODEL_NAME", "mistral:7b") 
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")

# --- 3. FUNCIÃ“N DE CONEXIÃ“N CON IA ---
def consultar_ollama(prompt_usuario, system_instruction):
    try:
        payload = {
            "model": MODEL_NAME, 
            "prompt": prompt_usuario, 
            "system": system_instruction,
            "stream": False,
            "options": {
                "temperature": 0.4,   # EQUILIBRADO: Creativo pero profesional
                "num_predict": 300,   
                "num_ctx": 4096       
            }
        }
        # Timeout de seguridad
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)
        return response.json().get("response", "Lo siento, tuve un problema interno al pensar la respuesta.")
    except Exception as e:
        logger.error(f"Error conectando con Ollama: {e}")
        return "âš ï¸ Vaya, parece que no puedo conectar con mi cerebro local (Ollama). Por favor revisa la terminal."

# --- 4. COMANDOS ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    nombre = update.effective_user.first_name
    await update.message.reply_text(
        f"Â¡Hola, {nombre}! ğŸ‘‹\n\n"
        "Soy MeetManager, tu asistente personal inteligente. "
        "Estoy aquÃ­ para ayudarte a organizar tu agenda, redactar correos y hacer tu trabajo mÃ¡s fÃ¡cil.\n\n"
        "Puedes escribirme como si fuera una persona o usar /help para ver mis herramientas."
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    texto = (
        "ğŸš€ **Â¿CÃ“MO PUEDO AYUDARTE?**\n\n"
        "AquÃ­ tienes mis funciones principales:\n\n"
        "ğŸ”¹ **/estado** â†’ Comprobar mi conexiÃ³n.\n"
        "ğŸ”¹ **/tips** â†’ Un consejo rÃ¡pido de productividad.\n"
        "ğŸ”¹ **/cita [texto]** â†’ Organizar una reuniÃ³n.\n"
        "ğŸ”¹ **/email [texto]** â†’ Redactar un correo profesional.\n"
        "ğŸ”¹ **/resumir [texto]** â†’ Sintetizar informaciÃ³n compleja.\n\n"
        "ğŸ’¬ **Chat Libre:** TambiÃ©n puedes preguntarme lo que quieras."
    )
    await update.message.reply_text(texto, parse_mode='Markdown')

async def sobre(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ¤– **Sobre MÃ­**\n"
        "Soy un asistente potenciado por Inteligencia Artificial (Mistral 7B) ejecutÃ¡ndose localmente en tu equipo.\n"
        "DiseÃ±ado para ser privado, rÃ¡pido y Ãºtil."
    )

async def estado(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        requests.get(OLLAMA_URL.replace("/api/generate", ""))
        msg = "ğŸŸ¢ **Sistemas Operativos:** Estoy conectado y listo para trabajar."
    except:
        msg = "ğŸ”´ **Error de ConexiÃ³n:** No detecto el servidor de Ollama. Â¿EstÃ¡ encendido?"
    await update.message.reply_text(msg, parse_mode='Markdown')

async def tips(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_chat_action(ChatAction.TYPING)
    prompt = "Dame un consejo Ãºtil, motivador y prÃ¡ctico para ser mÃ¡s eficiente en el trabajo hoy."
    res = consultar_ollama(prompt, "Eres un coach de productividad amable y claro.")
    await update.message.reply_text(f"ğŸ’¡ {res}")

async def cita(update: Update, context: ContextTypes.DEFAULT_TYPE):
    texto = " ".join(context.args)
    if not texto:
        await update.message.reply_text("ğŸ¤” Necesito que me des los detalles. Prueba